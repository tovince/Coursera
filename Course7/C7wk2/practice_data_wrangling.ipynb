{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# **Hands-on Practice Lab: Data Wrangling**\n\nEstimated time needed: **30** minutes\n\nIn this lab, you will use the skills acquired in the module and address the issues of handling missing data, correct the data type of the dataframe attribute and execute the processes of data standardization and data normalization on specific attributes of the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Objectives\n\nAfter completing this lab you will be able to:\n\n - Handle missing data in different ways\n - Correct the data type of different data values as per requirement\n - Standardize and normalize the appropriate data attributes\n - Visualize the data as grouped bar graph using Binning\n - Cnverting a categorical data into numerical indicator variables\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Setup\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "For this lab, we will be using the following libraries:\n\n* `skillsnetwork` to download the dataset\n*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for managing the data.\n*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Importing Required Libraries\n\n_We recommend you import all required libraries in one place (here):_\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Download the updated dataset by running the cell below.\n\nThe functions below will download the dataset into your browser:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "file_path= \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/laptop_pricing_dataset_mod1.csv\"",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "To obtain the dataset, utilize the download() function as defined above:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "await download(file_path, \"laptops.csv\")\nfile_name=\"laptops.csv\"",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "First we load data into a `pandas.DataFrame`:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(file_name, header=0)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "> Note: This version of the lab is working on JupyterLite, which requires the dataset to be downloaded to the interface.While working on the downloaded version of this notebook on their local machines(Jupyter Anaconda), the learners can simply **skip the steps above,** and simply use the URL directly in the `pandas.read_csv()` function. You can uncomment and run the statements in the cell below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#filepath = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/laptop_pricing_dataset_mod1.csv\"\n#df = pd.read_csv(filepath, header=None)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Verify loading by displaying the dataframe summary using `dataframe.info()`\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(df.info())",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "View the first 5 values of the updated dataframe using `dataframe.head()`\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.head()",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Note that we can update the `Screen_Size_cm` column such that all values are rounded to nearest 2 decimal places by using `numpy.round()`\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df[['Screen_Size_cm']] = np.round(df[['Screen_Size_cm']],2)\ndf.head()",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Task - 1\n\n### Evaluate the dataset for missing data\nMissing data was last converted from '?' to numpy.NaN. Pandas uses NaN and Null values interchangeably. This means, you can just identify the entries having Null values. Write a code that identifies which columns have missing data. \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute \n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for the solution</summary>\n\n```python\nmissing_data = df.isnull()\nprint(missing_data.head())\nfor column in missing_data.columns.values.tolist():\n    print(column)\n    print (missing_data[column].value_counts())\n    print(\"\")  \n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Task - 2\n\n### Replace with mean\nMissing values in attributes that have continuous data are best replaced using Mean value. We note that values in \"Weight_kg\" attribute are continuous in nature, and some values are missing. Therefore, write a code to replace the missing values of weight with the average value of the attribute.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<details>\n    <summary>Click here for the solution</summary>\n    \n```python\n# replacing missing data with mean\navg_weight=df['Weight_kg'].astype('float').mean(axis=0)\ndf[\"Weight_kg\"].replace(np.nan, avg_weight, inplace=True)\n\n# astype() function converts the values to the desired data type\n# axis=0 indicates that the mean value is to calculated across all column elements in a row.\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Replace with the most frequent value\nMissing values in attributes that have categorical data are best replaced using the most frequent value. We note that values in \"Screen_Size_cm\" attribute are categorical in nature, and some values are missing. Therefore, write a code to replace the missing values of Screen Size with the most frequent value of the attribute.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<details>\n    <summary>Click here for the solution</summary>\n    \n```python\n# replacing missing data with mode\ncommon_screen_size = df['Screen_Size_cm'].value_counts().idxmax()\ndf[\"Screen_Size_cm\"].replace(np.nan, common_screen_size, inplace=True)\n```\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Task - 3\n\n### Fixing the data types\nBoth \"Weight_kg\" and \"Screen_Size_cm\" are seen to have the data type \"Object\", while both of them should be having a data type of \"float\". Write a code to fix the data type of these two columns.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<details>\n    <summary>Click here for Solution</summary>\n\n```python\ndf[[\"Weight_kg\",\"Screen_Size_cm\"]] = df[[\"Weight_kg\",\"Screen_Size_cm\"]].astype(\"float\")\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Task - 4\n\n### Data Standardization\nThe value of Screen_size usually has a standard unit of inches. Similarly, weight of the laptop is needed to be in pounds. Use the below mentioned units of conversion and write a code to modify the columns of the dataframe accordingly. Update their names as well.\n\n```{math}\n1 inch = 2.54 cm\n1 kg   = 2.205 pounds\n```\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<details>\n    <summary>Click here for Solution</summary>\n\n```python\n# Data standardization: convert weight from kg to pounds\ndf[\"Weight_kg\"] = df[\"Weight_kg\"]*2.205\ndf.rename(columns={'Weight_kg':'Weight_pounds'}, inplace=True)\n\n# Data standardization: convert screen size from cm to inch\ndf[\"Screen_Size_cm\"] = df[\"Screen_Size_cm\"]/2.54\ndf.rename(columns={'Screen_Size_cm':'Screen_Size_inch'}, inplace=True)\n```\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Data Normalization\nOften it is required to normalize a continuous data attribute. Write a code to normalize the \"CPU_frequency\" attribute with respect to the maximum value available in the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<details>\n    <summary>Click here for Solution</summary>\n\n```python\ndf['CPU_frequency'] = df['CPU_frequency']/df['CPU_frequency'].max()\n```\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Task - 5\n\n### Binning\nBinning is a process of creating a categorical attribute which splits the values of a continuous data into a specified number of groups. In this case, write a code to create 3 bins for the attribute \"Price\". These bins would be named \"Low\", \"Medium\" and \"High\". The new attribute will be named \"Price-binned\".\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<details>\n    <summary>Click here for Solution</summary>\n\n```python\nbins = np.linspace(min(df[\"Price\"]), max(df[\"Price\"]), 4)\ngroup_names = ['Low', 'Medium', 'High']\ndf['Price-binned'] = pd.cut(df['Price'], bins, labels=group_names, include_lowest=True )\n```\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Also, plot the bar graph of these bins.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<details>\n    <summary>Click here for Solution</summary>\n\n```python\nplt.bar(group_names, df[\"Price-binned\"].value_counts())\nplt.xlabel(\"Price\")\nplt.ylabel(\"count\")\nplt.title(\"Price bins\")\n```\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Task - 6\n\n### Indicator variables\nConvert the \"Screen\" attribute of the dataset into 2 indicator variables, \"Screen-IPS_panel\" and \"Screen-Full_HD\". Then drop the \"Screen\" attribute from the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your code below and press Shift+Enter to execute\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<details>\n    <summary>Click here for Solution</summary>\n\n```python\n#Indicator Variable: Screen\ndummy_variable_1 = pd.get_dummies(df[\"Screen\"])\ndummy_variable_1.rename(columns={'IPS Panel':'Screen-IPS_panel', 'Full HD':'Screen-Full_HD'}, inplace=True)\ndf = pd.concat([df, dummy_variable_1], axis=1)\n\n# drop original column \"Screen\" from \"df\"\ndf.drop(\"Screen\", axis = 1, inplace=True)\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "This version of the dataset, now finalized, is the one you'll be using in all subsequent modules. \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Print the content of dataframe.head() to verify the changes that were made to the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(df.head())",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Congratulations! You have completed the lab\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "[Abhishek Gagneja](https://www.coursera.org/instructor/~129186572)\n\n[Vicky Kuo](https://author.skills.network/instructors/vicky_kuo)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Change Log\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n|-|-|-|-|\n|2023-09-15|0.1|Abhishek Gagneja|Initial Version Created|\n|2023-09-19|0.2|Vicky Kuo|Reviewed and Revised|\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Copyright Â© 2023 IBM Corporation. All rights reserved.\n",
      "metadata": {}
    }
  ]
}